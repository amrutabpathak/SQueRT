{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ProcessText.ipynb\n"
     ]
    }
   ],
   "source": [
    "# pip install pdfminer.six\n",
    "# pip install ipynb\n",
    "\n",
    "# Import statements go here\n",
    "\n",
    "import import_ipynb\n",
    "import ProcessText\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfdir = 'C:/Users/Evan/Documents/7180QueryTool/Data/'\n",
    "txtdir = 'C:/Users/Evan/Documents/7180QueryTool/DataTxt/'\n",
    "csvdir = 'C:/Users/Evan/Documents/7180QueryTool/DataCsv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape papers to pdf folder\n",
    "%run -i 'arxiv_pdf_scraper.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pdfs to text\n",
    "for research_paper_name in glob.glob(pdfdir + \"*.pdf\"):\n",
    "    ProcessText.pdfToText(research_paper_name, txtdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What model was introduced in this paper?\n"
     ]
    }
   ],
   "source": [
    "# Basic user interface; obtain query\n",
    "print(\"Query: What model was introduced in this paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_inference_learning_for_semi_supervised_classification.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "graph_inference_learning_for_semi_supervised_classification_3.csv\n",
      "Exit\n",
      "large_batch_optimization_for_deep_learning_training_bert_in_76_minutes.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "large_batch_optimization_for_deep_learning_training_bert_in_76_minutes_3.csv\n",
      "Exit\n",
      "learning_deep_graph_matching_with_channel_independent_embedding_and_hungarian_attention.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "learning_deep_graph_matching_with_channel_independent_embedding_and_hungarian_attention_3.csv\n",
      "Exit\n",
      "on_the_weaknesses_of_reinforcement_learning_for_neural_machine_translation.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "on_the_weaknesses_of_reinforcement_learning_for_neural_machine_translation_3.csv\n",
      "Exit\n",
      "reinforcement_learning_based_graph_to_sequence_model_for_natural_question_generation.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "reinforcement_learning_based_graph_to_sequence_model_for_natural_question_generation_3.csv\n",
      "Exit\n",
      "self_learning_to_filter_noisy_labels_with_self_ensembling.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "self_learning_to_filter_noisy_labels_with_self_ensembling_3.csv\n",
      "Exit\n",
      "sharing_knowledge_in_multi_task_deep_reinforcement_learning.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "sharing_knowledge_in_multi_task_deep_reinforcement_learning_3.csv\n",
      "Exit\n",
      "sqil_imitation_learning_via_reinforcement_learning_with_sparse_rewards.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "sqil_imitation_learning_via_reinforcement_learning_with_sparse_rewards_3.csv\n",
      "Exit\n",
      "structpool_structured_graph_pooling_via_conditional_random_fields.txt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt\n",
      "C:/Users/Evan/Documents/7180QueryTool/DataTxt/snippet_data\n",
      "structpool_structured_graph_pooling_via_conditional_random_fields_3.csv\n",
      "Exit\n"
     ]
    }
   ],
   "source": [
    "# Convert text files to CSV snippets\n",
    "sentenceNum = 3\n",
    "for research_paper_name in glob.glob(txtdir + \"*.txt\"):\n",
    "    ProcessText.snippetToCsv(research_paper_name, sentenceNum, csvdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from USEmodel.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Use USE to obtain best snippets for query\n",
    "import USEmodel\n",
    "csvdir = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run BERT on best snippets, return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
