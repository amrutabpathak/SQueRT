en_trf_bertbaseuncased_lg
Which model is proposed in the paper?
Note that the last one fr defines on the former two ones  so we consider the cases in Table 4 by adding modules.When not using all modules  only original attributes of nodes are used to predict labels.The case of only using fe belongs to the GCN method  which can achieve 81.5% on the Cora dataset.
0.7048881735002095
Which model is proposed in the paper?
Marginalized kernels between labeled graphs. In ICML  pp 321–328  2003. Thomas N. Kipf and Max Welling.
0.7054130903880446
Which model is proposed in the paper?
 1  Published as a conference paper at ICLR 2020  Figure 1: The illustration of our proposed GIL framework.For the problem of graph node labeling  the category information of these unlabeled nodes depends on the similarity computation between a query node (e.g.  vj) and these labeled reference nodes (e.g.  vi).We consider the similarity from three points: node attributes  the consistency of local topological structures (i.e.  the circle with dashed line)  and the between-node path reachability (i.e.  the red wave line from vi to vj).
0.7076068735418505
Which model is proposed in the paper?
We further improve the inference learning capability of the GIL model for 1200 iterations with the validation set  where the meta-learning rates α and β are both set to 0.001. 6  Published as a conference paper at ICLR 2020  5.2 COMPARISON WITH STATE-OF-THE-ARTS  We compare the GIL approach with several state-of-the-art methods (Monti et al  2017; Kipf & Welling  2017; Zhou et al  2004; Zhuang & Ma  2018) over four graph datasets  including Cora  Citeseer  Pubmed  and NELL.The classification accuracies for all methods are reported in Table 2.
0.7081328019455344
Which model is proposed in the paper?
These aforementioned works usually boil down to a general classification task  where the model is learnt on a training set and selected by checking a validation set.However  they do not put great efforts on how to learn to infer from one node to another node on a topological graph  especially in the few-shot regime. In this paper  we propose a graph inference learning (GIL) framework to teach the model itself to adaptively infer from reference labeled nodes to those query unlabeled nodes  and finally boost the performance of semi-supervised node classification in the case of a few number of labeled samples.
0.7127380415210145
Which model is proposed in the paper?
In other words  the validation set is only used to teach the model itself how to transfer to unseen data.In contrast  the conventional methods often employ a validation set to tune parameters of a certain model of interest. Table 3: Performance comparisons with several GIL variants and the classical GCN method on the Cora dataset.
0.7144274574339029
Which model is proposed in the paper?
In the extreme case  labels of unlabeled nodes could be determined by those neighbors with the 1 ∼ 2 step reachability.In summary  our proposed GIL method prefers small ratio labeled nodes on the semi-supervised node classification task. Inference learning process: Classification errors of different epochs on the validation set of the Cora dataset can be illustrated in Fig 3.
0.7145538101793715
Which model is proposed in the paper?
In IJCAI  pp 2609–2615  2018. Sachin Ravi and Hugo Larochelle.Optimization as a model for few-shot learning.
0.7168673991221539
Which model is proposed in the paper?
Inspired by the recent meta-learning strategy (Finn et al  2017)  we learn to infer the structure relations from a training set to a validation set  which can benefit the generalization capability of the learned model.In other words  our proposed GIL attempts to learn some transferable knowledge underlying in the structure relations from training samples to validation samples  such that the learned structure relations can be better self-adapted to the new testing stage. We summarize the main contributions of this work as three folds:  • We propose a novel graph inference learning framework by building structure relations to infer unknown node labels from those labeled nodes in an end-to-end way.
0.7275211639327663
Which model is proposed in the paper?
In the standard protocol  3  Published as a conference paper at ICLR 2020  of prior literatures (Yang et al  2016)  the three node sets share the same label space.We follow but do not restrict this protocol for our proposed method.Given the training and validation node sets  the aim is to predict the node labels of testing nodes by using node attributes as well as edge connections.
0.7446642796062042





en_trf_robertabase_lg
Which model is proposed in the paper?
In ICML  pp 912–919  2003. Chenyi Zhuang and Qiang Ma. Dual graph convolutional networks for graph-based semi-supervised  classification.In WWW  pp 499–508  2018.
0.972996467125455
Which model is proposed in the paper?
In Artificial Intelligence and Statistics  pp 488–495  2009. Flood Sung  Li Zhang  Tao Xiang  Timothy Hospedales  and Yongxin Yang.Learning to learn:  Meta-critic networks for sample efficient learning. arXiv preprint arXiv:1706.09529  2017.
0.9730043061880344
Which model is proposed in the paper?
In CVPR  pp 5115–5124  2017. Christopher Morris  Kristian Kersting  and Petra Mutzel.Glocalized weisfeiler-lehman graph kernels:  Global-local feature maps of graphs.
0.973018890315477
Which model is proposed in the paper?
The structure relations are well defined by jointly considering node attributes  between-node paths  and graph topological structures. • To make the inference model better generalize to test nodes  we introduce a meta-learning procedure to optimize structure relations  which could be the first time for graph node classification to the best of our knowledge. • Comprehensive evaluations on three citation network datasets (including Cora  Citeseer  and Pubmed) and one knowledge graph data (i.e.  NELL) demonstrate the superiority of our proposed GIL in contrast with other state-of-the-art methods on the semi-supervised classification task.
0.9736182605931338
Which model is proposed in the paper?
Although graph CNN based methods have achieved considerable capabilities of graph embedding by optimizing filters  they are limited into a conventionally semi-supervised framework and lack of an efficient inference mechanism on graphs.Especially  in the case of few-shot learning  where a small number of training nodes are labeled  this kind of methods would drastically compromise the performance.For example  the Pubmed graph dataset (Sen et al  2008) consists  ∗Corresponding author: Zhen Cui.
0.9739542404375261
Which model is proposed in the paper?
N-gcn: Multi-scale graph  convolution for semi-supervised node classification. arXiv preprint arXiv:1802.08888  2018. James Atwood and Don Towsley.Diffusion-convolutional neural networks.
0.9739923443388321
Which model is proposed in the paper?
Note that the last one fr defines on the former two ones  so we consider the cases in Table 4 by adding modules.When not using all modules  only original attributes of nodes are used to predict labels.The case of only using fe belongs to the GCN method  which can achieve 81.5% on the Cora dataset.
0.9758003267418321
Which model is proposed in the paper?
A sophisticated machine learning technique used in most existing methods (Kipf & Welling  2017; Zhou et al  2004) is to choose the optimal classifier (trained on a training set) after checking the performance on the validation set.However  these methods essentially ignore how to extract transferable knowledge from these known labeled nodes to unlabeled nodes  as the graph structure itself implies node connectivity/reachability.Moreover  due to the scarcity of labeled samples  the performance of such a classifier is usually not satisfying.
0.9759008958912916
Which model is proposed in the paper?
In IJCAI  pp 2609–2615  2018. Sachin Ravi and Hugo Larochelle.Optimization as a model for few-shot learning.
0.9771008162565109
Which model is proposed in the paper?
In the standard protocol  3  Published as a conference paper at ICLR 2020  of prior literatures (Yang et al  2016)  the three node sets share the same label space.We follow but do not restrict this protocol for our proposed method.Given the training and validation node sets  the aim is to predict the node labels of testing nodes by using node attributes as well as edge connections.
0.9777341558915578




en_trf_distilbertbaseuncased_lg
Which model is proposed in the paper?
In the testing stage  we may take all training nodes and perform the model update according to Eqn (6) like the training process.The updated model is used as the final model and is then fed into Eqn (2) to infer the class labels for those query nodes. 4 MODULES In this section  we instantiate all modules (i.e.  functions) of the aforementioned structure relation.
0.7972509598166319
Which model is proposed in the paper?
These aforementioned works usually boil down to a general classification task  where the model is learnt on a training set and selected by checking a validation set.However  they do not put great efforts on how to learn to infer from one node to another node on a topological graph  especially in the few-shot regime. In this paper  we propose a graph inference learning (GIL) framework to teach the model itself to adaptively infer from reference labeled nodes to those query unlabeled nodes  and finally boost the performance of semi-supervised node classification in the case of a few number of labeled samples.
0.8013123217599453
Which model is proposed in the paper?
To address these issues  we introduce a meta-learning mechanism (Finn et al  2017; Ravi & Larochelle  2017; Sung et al  2017) to learn to infer node labels on graphs.Specifically  the graph structure  between-node path reachability  and node attributes are jointly modeled into the learning process.Our aim is to learn to infer from labeled nodes to unlabeled nodes  so that the learner can perform better on a validation set and thus classify a testing set more accurately.
0.8024182620656102
Which model is proposed in the paper?
The structure relations are well defined by jointly considering node attributes  between-node paths  and graph topological structures. • To make the inference model better generalize to test nodes  we introduce a meta-learning procedure to optimize structure relations  which could be the first time for graph node classification to the best of our knowledge. • Comprehensive evaluations on three citation network datasets (including Cora  Citeseer  and Pubmed) and one knowledge graph data (i.e.  NELL) demonstrate the superiority of our proposed GIL in contrast with other state-of-the-art methods on the semi-supervised classification task.
0.8040909816711206
Which model is proposed in the paper?
In the extreme case  labels of unlabeled nodes could be determined by those neighbors with the 1 ∼ 2 step reachability.In summary  our proposed GIL method prefers small ratio labeled nodes on the semi-supervised node classification task. Inference learning process: Classification errors of different epochs on the validation set of the Cora dataset can be illustrated in Fig 3.
0.8050544898165518
Which model is proposed in the paper?
Marginalized kernels between labeled graphs. In ICML  pp 321–328  2003. Thomas N. Kipf and Max Welling.
0.809061112935431
Which model is proposed in the paper?
In IJCAI  pp 2609–2615  2018. Sachin Ravi and Hugo Larochelle.Optimization as a model for few-shot learning.
0.8095728798972796
Which model is proposed in the paper?
In other words  the validation set is only used to teach the model itself how to transfer to unseen data.In contrast  the conventional methods often employ a validation set to tune parameters of a certain model of interest. Table 3: Performance comparisons with several GIL variants and the classical GCN method on the Cora dataset.
0.8177660384725728
Which model is proposed in the paper?
Inspired by the recent meta-learning strategy (Finn et al  2017)  we learn to infer the structure relations from a training set to a validation set  which can benefit the generalization capability of the learned model.In other words  our proposed GIL attempts to learn some transferable knowledge underlying in the structure relations from training samples to validation samples  such that the learned structure relations can be better self-adapted to the new testing stage. We summarize the main contributions of this work as three folds:  • We propose a novel graph inference learning framework by building structure relations to infer unknown node labels from those labeled nodes in an end-to-end way.
0.8202381117955608
Which model is proposed in the paper?
In the standard protocol  3  Published as a conference paper at ICLR 2020  of prior literatures (Yang et al  2016)  the three node sets share the same label space.We follow but do not restrict this protocol for our proposed method.Given the training and validation node sets  the aim is to predict the node labels of testing nodes by using node attributes as well as edge connections.
0.8231754184383792





Google_USE
Which model is proposed in the paper?
The normalization factor FCc→vj of the c-th category w.r.t. vj is defined as  (2)  (4)  For the relation function φr and the weight function φw  we may choose some subnetworks to instantiate them in practice.The detailed implementation of our model can be found in Section 4. FCc→vj =  (cid:80)  1  vi∈Cc  wi→j  4  Published as a conference paper at ICLR 2020  3.3  INFERENCE LEARNING  According to the class-to-node relationship function in Eqn (2)  given a query node vj  we can obtain a score vector sC→j = [sC1→j  · · ·   sCC →j](cid:124) ∈ RC after computing the relations to all classesThe indexed category with the maximum score is assumed to be the estimated label.
[[0.48372245]]
Which model is proposed in the paper?
Another type of graph CNNs  namely spatial methods (Li et al  2016; Niepert et al  2016)  can perform the filtering operation by defining the spatial structures of adjacent vertices.Various approaches can be employed to aggregate or sort neighboring vertices  such as diffusion CNNs (Atwood & Towsley  2016)  GraphSAGE (Hamilton et al  2017)  PSCN (Niepert et al  2016)  and NgramCNN (Luo et al  2017).From the perspective of data distribution  recently  the Gaussian induced convolution model (Jiang et al  2019) is proposed to disentangle the aggregation process through encoding adjacent regions with Gaussian mixture model.
[[0.484939]]
Which model is proposed in the paper?
 Jian Du  Shanghang Zhang  Guanhang Wu  José MF Moura  and Soummya Kar.Topology adaptive  graph convolutional networks. arXiv preprint arXiv:1710.10370  2017. Chelsea Finn  Pieter Abbeel  and Sergey Levine.
[[0.4859532]]
Which model is proposed in the paper?
N-gcn: Multi-scale graph  convolution for semi-supervised node classification. arXiv preprint arXiv:1802.08888  2018. James Atwood and Don Towsley.Diffusion-convolutional neural networks.
[[0.4903173]]
Which model is proposed in the paper?
AI magazine  29(3):93–93  2008. Nino Shervashidze  SVN Vishwanathan  Tobias Petri  Kurt Mehlhorn  and Karsten Borgwardt.Efficient graphlet kernels for large graph comparison.
[[0.4905582]]
Which model is proposed in the paper?
 (8)  (9)  5 EXPERIMENTS  5.1 EXPERIMENTAL SETTINGS  We evaluate our proposed GIL method on three citation network datasets: Cora  Citeseer  Pubmed (Sen et al  2008)  and one knowledge graph NELL dataset (Carlson et al  2010).The statistical properties of graph data are summarized in Table 1.Following the previous protocol in (Kipf & Welling  2017; Zhuang & Ma  2018)  we split the graph data into a training set  a validation set  and a testing set.
[[0.4923216]]
Which model is proposed in the paper?
In the future  we would extend the graph inference method to handle more graph-related tasks  such as graph generation and social network analysis. 9  the number of iterations error Published as a conference paper at ICLR 2020  ACKNOWLEDGMENT  This work was supported by the National Natural Science Foundation of China (Nos 61972204  61906094  U1713208)  the Natural Science Foundation of Jiangsu Province (Grant Nos.BK20191283 and BK20190019)  and Tencent AI Lab Rhino-Bird Focused Research Program (No.
[[0.49622482]]
Which model is proposed in the paper?
 Methods Clustering (Brandes et al  2008) DeepWalk (Zhou et al  2004) Gaussian (Zhu et al  2003) G-embedding (Yang et al  2016) DCNN (Atwood & Towsley  2016) GCN (Kipf & Welling  2017) MoNet (Monti et al  2017) N-GCN (Abu-El-Haija et al  2018) GAT (Velickovic et al  2018) AGNN (Thekumparampil et al  2018) TAGCN (Du et al  2017) DGCN (Zhuang & Ma  2018) Our GIL  Cora 59.5 67.2 68.0 75.7 76.8 81.5 81.7 83.0 83.0 83.1 83.3 83.5 86.2  Citeseer 60.1 43.2 45.3 64.7 - 70.3 - 72.2 72.5 71.7 72.5 72.6 74.1  Pubmed NELL 70.7 65.3 63.0 77.2 73.0 79.0 78.8 79.5 79.0 79.9 79.0 80.0 83.1  21.8 58.1 26.5 61.9 - 66.0 - - - - - 74.2 78.9  5.3 ANALYSIS  Meta-optimization: As can be seen in Table 3  we report the classification accuracies of semi-supervised classification with several variants of our proposed GIL and the classical GCN method (Kipf & Welling  2017) when evaluating them on the Cora dataset.For analyzing the perfor- mance improvement of our proposed GIL with the graph inference learning process  we report the classification accuracies of GCN (Kipf & Welling  2017) and our proposed GIL on the Cora dataset under two different situations  including “only learning with the training set Vtr" and “with jointly learning on a training set Vtr and a validation set Vval".“GCN /w jointly learning on Vtr & Vval" achieves a better result than “GCN /w learning on Vtr" by 3.6%  which demonstrates that the network performance can be improved by employing validation samples.
[[0.49640283]]
Which model is proposed in the paper?
We further improve the inference learning capability of the GIL model for 1200 iterations with the validation set  where the meta-learning rates α and β are both set to 0.001. 6  Published as a conference paper at ICLR 2020  5.2 COMPARISON WITH STATE-OF-THE-ARTS  We compare the GIL approach with several state-of-the-art methods (Monti et al  2017; Kipf & Welling  2017; Zhou et al  2004; Zhuang & Ma  2018) over four graph datasets  including Cora  Citeseer  Pubmed  and NELL.The classification accuracies for all methods are reported in Table 2.
[[0.5091791]]
Which model is proposed in the paper?
IEEE Transactions on Knowledge and Data Engineering  29(10): 2125–2139  2017. 10  Published as a conference paper at ICLR 2020  Federico Monti  Davide Boscaini  Jonathan Masci  Emanuele Rodola  Jan Svoboda  and Michael M Bronstein.Geometric deep learning on graphs and manifolds using mixture model cnns.
[[0.52311116]]
